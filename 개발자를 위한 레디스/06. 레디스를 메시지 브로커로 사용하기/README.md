# 레디스를 메시지 브로커로 사용하기
마이크로서비스 아키텍처는 여러 모듈이 서로 느슨하고 적절하게 연결시킨 구조를 선호  
효율적인 메시징 솔루션, 메시지 브로커를 필요로한다.  

서비스간 커넥션이 실패하는 상황은 언제나 발생 가능  
모듈간의 통신은 되도록 비동기 통신을 사용하는 것을 권장하며 동시 통신의 횟수를 최대한 줄이는 것이 바람직하다.  
당장 메시지를 처리하지 못하더라도 보낸 메시지를 어딘가에 쌓아 둔 뒤 나중에 처리할 수 있는 채널을 만들어 주는것 이것이 메시지 브로커의 핵심역하링라 할 수 있다.  

메시지 브로커는 크게 메시징 큐와 이벤트 스트림이라는 두 가지 형태로 나눌 수 있다.

## 메시징 큐와 이벤트 스트림

### 메시징 큐
메시징 큐에서는 데이터를 생성하는 쪽을 생산자(producer), 데이터를 수신하는 쪽을 소비자(consumer)라고 부른다.  

### 이벤트 스트림
이벤트 스트림은 메시징 큐와 비슷하지만, 데이터를 생성하는 쪽을 발행자(publisher), 데이터를 수신하는 쪽을 구독자(subscriber)라고 부른다.  

메시징 큐와 이벤트 스트림은 크게 두 가지 차이점이 있다.  
첫번째는 방향성이다.  
메시징 큐의 생상자는 소비자의 큐로 데이터를 직접 푸시한다.  
2개의 서비스에 같은 메시지를 보내야할 때 메시징 큐를 이용한다면 생산자는 2개의 각각 다른 메시징 큐에 각각 데이터 푸시해야한다.  
반면 스트림을 이용한다면 생산자는 스트림의 특정 저장소에 하나의 메시지를 보낼 수 있고, 메시지를 읽는 쪽 소비자는 스트림에서 같ㅌ은 메시지를 풀해갈 수있기 때문에
메시지를 복제해서 저장하지 않아도 된다.  

두번째는 데이터 영속성이다.  
메시징 큐에서는 소비자가 데이터를 읽어갈 때 큐에서 데이터를 삭제한다.  
하지만 이벤트 스트림에서 구독자가 읽어간 데이터는 바로 삭제되지 않고 저장소의 설정에 따라 특정 기간 동안 저장될 수 있다.  

메시징 큐에서 새로운 소비자를 추가할 때, 새로운 소비자는 추가 된 이후의 이벤트만 확인할 수 있다.  
하지만 스트림 방식에서는 메시지를 생산할 때 구독자를 지정하지 않고, 스트림에 쌓인 데이터는 일정 기간 지워지지 않기 때문에 새로 추가된 서비스도
스트림에 남아 있는 이전 데이터의 히스토리를 볼 수 있다.  

따라서 메시징 큐는 1대1 상황에서 한 서비스가 다른 서비스에게 동작을 지시 할 때 유용하게 사용될 수 있으며,  
스트림은 다대다 상황에서 유리함을 확인할 수 있다.  

## 레디스를 메시지 브로커로 사용하기
레디스에서 제공하는 pub/sub을 사용하면 빠르고 간단한 방식으로 메시지를 전달할 수 있는 메시지 브로커를 구현할 수 있다.  
발행자가 특정한 채널에 데이터를 전송하면 이 채널을 듣고 있는  모든 소비자는 데이터를 바로 소비할 수 있다.  
하지만 이 데이터는 한번 전달하면 사라지는 일회성이고 잘 전달했는지 등의 정보는 보장하지 않는다.  
따라서 완벽하게 미시지가 전달돼야 하는 상황에서는 적합하지 않을 수도 있지만 fire-and-forget 패턴이 필요한 간단한 알림 서비스에서는 유용하게 사용될 수 있다.

레디스의 list는 메시징 큐로 사용하기 알맞다. 데이터의 푸시와 팝이 가능하며 list에 데이터가 있는지 매번 확인할 필요가 없이 대기하다
list에 새로운 데이터가 들어오면 읽어갈 수 있는 블로킹 기능을 사용할 수 도 있다.  

레디스의 stream을 사용하면 레디스를 완벽히 스트림 플랫폼으로 사용할 수 있다.  
카프카 시스템에서 영감을 받아 만들었고, 데이터는 계속해서 추가되는 방식으로 저장된다.  
소비자와 소비자 그룹이라는 개념을 이용하면 카프카에서와 비슷하게 데이터의 분산 처리를 구현할 수 있다.  
메시지를 실시간으로 리스닝하며 소비할 수도 있으며, 저장돼 있는 데이터를 시간대별로 검색하는 것도 가능하다.

# 레드시의 pub/sub
레디스 노드에 접근할 수 있는 모든 클라이언트는 발행자와 구독자가 될 수 있다.  
메타데이터는 알 수 없으므로 중요한 데이터를 전달하기에는 적합하지 않다.  

### 메시지 publish 하기
```redis
publish hello world
```
hello 채널을 수신하는 모든 구독자에게 world라는 메시지를 전달한다.

### 메시지 구독하기
```redis
subscribe hello hello2
```
hello 채널과 hello2 채널을 구독한다.

subscribe, ssubscribe, sunsubscribe, punsubscribe, psubscribe, unsubscribe, ping reset, quit 명령어를 사용할 수 있다.  

psubscribe
```redis
psubscribe hello-*
```
hello-로 시작하는 모든 채널을 구독한다.  
만약 hello-1과 hello-*를 구독하고 있으면 2개의 메시지를 받는다.  

## 클러스터 구조에서늬 pub/sub
메시지를 발행하면 해당 메ㅣ지는 클러스터에 속한 모든 노드에 자동으로 전달한다.  
따라서 레디스 클러스터의 아무 노드에 연결해 구독하면 데이터를 수신할 수 있다.  
하나의 노드에 메시지를 발행하면 모든 노드에 전파된다.  
이 방법은 굉장히 명료하지만 클러스터의 주요 목적을 고려한다면 비효율적인 방식으로 여겨질 수 있다.  
클러스터는 대규모 서비스에서 데이터를 분산해서 저장하고 처리하기 위해 도입되었고, 그렇기 때문에 클러스터 내에서 
pub/sub을 사용할때 메시지가 모든 레디스 노드에 복제되는 방식은 클러스터 환경의 핵임 목표와는 부합하지 않을 수 있다.  

## sharded pub/sub
위의 비효율을 해결하기 위해 레드시 7.0에서는 sharded pub/sub 기능이 도입 됐다.  
sharded pub/sub은 각 채널은 슬롯에 매핑된다.  
클러스터에서 키가 슬롯에 해당되는 것돠 동일한 방식으로 채널이 할당되며 같은 슬록을 가지고 있는 노드 간에만 pub/sub 메시지를 전파한다.  
클러스터 구조에서 pub/sub되는 메시지는 모든 노드로 전파되지 않기 때문에 불필요한 복제를 줄여 자원을 절약할 수 있다는 장점이 있다.

# 레디스의 list를 메시징 큐로 사용하기
레디스의 list는 tail과 head에서 데이터를 넣고 뺄 수 있는 lpush, lpop, rpush, rpop 커맨드가 존재하기 때문에 애플리케이션 특성에 맞는 메시징 큐를 직접 구현할 수 있다.  

## list의 ex 기능
이 내용은 트위터의 로직관리자인 라피 크리코리안이 2013년에 qcon 웨비나에서 발표한 내용을 바탕으로 한다.  

sns는 유저마다 각각 다른 타임라인을 가진다.  

트위터는 각 유저의 타임라인 캐시 데이터를 레디스에서 list 자료구조로 관리한다.  
유저 A가 새로운 트윗을 작성하면 그 데이터는 A를 팔로우하는 유저의 타임라인 캐시에 저장된다.  
A가 쓴 트윗의 데이터는 유저 B와 C의 타임라인 캐시 list에 새로운 아이템으로 추가된다.  

이때 각 타임라인 캐시에 데이터를 저장할 때는 rpush가 아닌 rpushx 커맨드를 사용함으로써 해당 리스트가 이미 존재할 때만 아이템을 추가하는 커맨드이다.  
이 커맨드를 사용하면 이미 캐시된 타임라인에만 데이터를 추가할 수 있다.  
자주 트위터를 들어오지 않는 D 유저에 대해서는 타임라인 캐시 데이터를 굳이 관리해야할 필요가 없기 때문이다.

```redis
rpushx timelinecache:userB data1
rpushx timelinecache:userC data1
rpushx timelinecache:userD data1
```
사용자의 캐시 유무를 애플리케이션에서 확인하는 과정이 아니라 모든 로직을 레디스에서 제어할 수 있기 때문에 불필요한 과정을 줄여 성능을 향상시킬 수 있다.

## list의 블로킹 기능
레디스를 이벤트 큐로 사용할 경우 블로킹 기능 또한 유용하게 사용할 수 있다.  
이벤트 기반 구조에서 시스템은 이벤트 루프를 돌며 신규로 처리할 이벤트가 있는지 체크한다.  

이벤트 루프는 이벤트 큐에 새 이벤트가 있는지 체크하며 새로운 이벤트가 없을 경우 정해진 시간 동안 대기한 뒤 다시 이벤트 큐에 데이터가 있는지 확인하는 과정을 반복한다.  
이러한 작업을 폴링이라고 하며 폴링 프로세스가 진행되는 동안 애플리케이션과 큐의 리소스가 불필요하게 소모될 수 있다.  
또한 이벤트 큐에 이벤트가 들어왔을 수 있지만, 폴링 인터벌 시간 동안은 대기한 뒤 다시 확인하는 과정을 거치기 때문에 이벤트를 즉시 처리할 수 없다는 단점이 있다.  

이때 list의 블로킹 기능을 사용하면 이와 같은 불필요함을 줄일 수 있다.  
brpop과 blpop은 각각 rpop, lpop에 블로킹을 추가한 커맨드이다.  
클라이언트가 blpop을 사용하면 리스트에 데이터가 있으면 즉시 반환한다.  
만약 데이터가 없을 경우에는 list에 데이터가 들어올 때 까지 기다린 후에 들어온 값을 반환하거나 클라이언트가 설정한 타임아웃시간만큼 대기한 후에 nil값을 반환한다.  

```redis
brpop queue:a 5
```
queue:a 리스트에 데이터가 들어오면 즉시 반환하고, 데이터가 없을 경우 5초 동안 대기한 후에 nil을 반환한다.  
타임아웃을 0으로 하면 데이터가 리스트에 들어올때까지 기다리며 하나의 리스트에 대해 여러 클라이언트가 동시에
블로킹 될 수 있으며, 리스트에 데이터가 입력되면 가장 먼저 요청을 보낸 클라이언트가 데이터를 가져간다.  

brpop은 bpop과 다르게 2개의 데이터를 반환한다.  
첫번째는 팝된 리스트의 키 값을 반환하고 두번째에 반환된 데이터의 값을 반환한다.  
이렇게 설계된 이유는 동시에 여러개의 리스트에서 대기할 수 있게 하기 위해서다.
```redis
brpop queue:a queue:b queue:c timeout 5
1) "queue:a"
2) "data1"
(19.89s)
```
위의 커맨드는 queue:a, queue:b, queue:c 중 하나의 리스트에 데이터가 들어오면 즉시 반환하고, 데이터가 없을 경우 5초 동안 대기한 후에 nil을 반환한다.
19.89초 동안 세 리스트에서 데이터가 입력되는 것을 기다렸다가 queue:a에 데이터가 입력되면 즉시 반환한다.  

## list를 이용한 원형 큐
만약 특정 아이템을 계속해서 반복 접근해야 하는 클라이언트, 혹은 여러 개의 클라이언트가 병렬적으로 같은 아이템에 접근해야 하는 클라이언트에서는 원형 큐를 이용해 아이템을 처리하고 싶을 수 있다.
rpoplpush 커맨드를 사용하면 간편하게 원형 큐를 사용할 수 있다.

```redis
lpush clist A
lpush clist B
lpush clist C
lrange clist 0 -1
rpoplpush clist clist
lrange clist 0 -1
// CBA 순서였던 리스트가 rpoplpush를 사용하여 ACB순서로 바뀌었다.
```

## Stream
stream은 레디스 5.0 에서 새로 추가된 자료 구조로 대용향, 대규모의 메시징 데이터를 빠르게 처리할 수 있도록 설계됐다.  
일반적으로 로그가 파일의 내용을 업데이트하거나 지우지 않고 쌓기만 하는 것처럼 stream 또한 데이터를 계속해서 추가하는 방식으로 저장되는 자료구조다.  

첫번째로 백엔드 개발자들은 stream을 대용량 데이터를 효율적으로 처리하는 플랫폼으로 활용한다.  
두번째로 데이터 엔지니어들은 stream을 여러 생산자가 생성한 데이터를 다양한 소비자가 처리할 수 있게 지원하는 데이터 저장소 및 중간 큐잉 시스템으로 사용할 수 있다.  

## 스트림이란?
컴퓨터 과학에서 스트림이란 연속적인 데이터의 흐름, 일정한 데이터 조각의 연속을 의미한다.  

10gb의 텍스트 파일을 처리하는 애플리케이션에서 바이트 스트림을 처리하는 과정은 다음과 같다.  
파일 하나는 유한하지만 이를 읽어올때 애플리케이션은 단어 단위, 또는 줄 단위로 데이터를 잘게 쪼개서 처리하기 때문에
프로그램은 바이트 스트림을 처리하는 것이라고 생각할 수 있다.  

끝이 정해지지 않고 계속되는 불규칙한 데이터를 연속으로 반복처리할 때 이 또한 스트림 처리를 한다고 부를 수 있다.  

채팅 프로그램에서 json 파일을 스트리밍 하는 과정은 채팅앱에서 사용자는 아무때나 채팅을 보낼 수 있으며 메신저 서버는 사람들이 계속 채팅하는 동안 끝없이 데이터를 
처리할 수 있어야 한다.  
메신저 서버는 사람들이 계속 채팅하는 동안 끝없이 데이터를 처리할 수 있어야한다.  
따라서 이 상황에서 서버는 json 스트림을 처리하는 것이라고 볼 수 있다.  

## 데이터의 저장
### 메시지의 저장과 식별
카프카에서 스트림 데이터는 토픽이라는 개념에 저장된다. 토픽은 각각의 분리된 스트림을 뜻하며 같은 데이터를 관리하는 하나의 그룹을 의미한다.  

레디스에서는 하나의 stream 자료 구조가 하나의 stream을 의미한다.  
레디스의 string, hash, set 등의 다른 자료구조와 마찬가지로 stream 형태의 자료 구조가 존재하며,
각 자료 구조가 하나의 키에 연결되는 것과 마찬가지로 stream 또한 하나의 키에 연결된 자료 구조다.  

카프카에서 각 메시지는 0부터 시작해서 증가하는 시퀀스 넘버로 식별할 수 있고,  
시퀀스 넘버는 각 토픽 내의 파티션 안에서만 유니크하게 증가하기 때문에 토픽이 1개 이상의 파티션을 갖는다면 메시지는 하나의 토픽내에서 유니크하게 식별되지 않는다.  
레디스 stream에서는 각 메시지는 시간과 관련된 유니크한 ID를 가지며, 이 값은 중복 되지 않는다.  
ID는 다음과 같이 2개의 파트로 나뉜다.
```redis
<밀리세컨드 단위의 타임스탬프>-<시퀀스 넘버>
```

밀리세컨드 파트는 실제 steram에 아이템이 저장될 시점의 레디스 노드 로컬 시간이다.  
시쿠너스 파트는 동일한 밀리세컨드 시간에 여러 아이템이 저장될 수 있으므로 같은 밀리세컨드에 저장된 데이터의 순서를 의미한다.  
시퀀스 번호는 64bit로 사실상 하나의 밀리세컨드 내에 생성할 수 있는 항목 수에는 제한이 없는것 같다.  

레디스 stream에 저장된 모든 데이터는 유니크한 ID를 가지며 이 Id 값이 곧 시간을 의미하기 때문에 시간을 이용해 특정 데이터를 검색할 수 있다.

### 스트림 생성과 데이터 입력
카프카에서 각 스트림은 토픽이란 이름으로 관리 된다.
생성자는 데이터를 토픽에 푸시하며 소비자는 토픽에서 데이터를 읽어간다.
카프카에서는 데이터를 저장하기 위해 토픽을 먼저 생성한뒤, 프로듀서를 이용해 메시지를 보낼 수 있다.
```kafka
-- 토픽 생성
kafka-topics --zookeeper 127.0.0.1:6000 --topic Email --create --partitions 1 --replication-factor 1

-- 데이터 추가
kafka-console-consumer --brokers-list 127.0.0.1:7000 --topic Email
```

레디스에서는 따로 stream을 생성하는 과정은 필요하지 않으면 xadd 커맨드를 사용해 새로운 이름의 stream에 데이터를 저장하면 데이터의 저장과 동시에 stream 자료 구조가 생긴다.

```redis
xadd email * subject "first" body "hello?"
"188888-0"
```
email이라는 이름의 stream에 subject와 body라는 필드를 가진 데이터를 저장하고, 이 데이터는 188888 밀리세컨드 시간에 저장됐으며 시퀀스 넘버는 0이다.  
이때 사용한 * 필드는 저장되는 데이터의 ID를 의미하며 이 값을 *로 입력하면 레디스에서 자동 생성되는 타임스탬프 ID를 사용하겠다는 것을 의미한다.  

메시지는 키 값 쌍으로 저장되며 위의 예제에서 subject라는 키에는 first값을, body라는 키에는 hello?라는 값이 저장된다.  
반환 값을 ID이다.

```redis
xadd push * userid 1000 ttl 3 body hey

xadd email * subject "second" body "hi?"
```
push라는 stream 자료구조가 생성되며 해당 stream에 데이터가 저장된다.  
두번째는 email stream이 이미 존재하기 때문에 새로운 메시지가 email stream에 저장된다.  
자동 생성 Id말고 직접 Id를 입력하고 싶다면 다음과 같이 입력하면 된다.
```redis
xadd mystrema 0-1 "hello" "world"
```
이때 id 최소 값은 0-1이고 이후에 저장되는 id는 전제 저장했던 id보다 작아질 수 없다.

### 데이터의 조회
카프카에서 소비자는 특정 토픽을 실시간으로 리스닝하며 새롭게 토픽에 저장되는 메시지를 받을 수 있다.  
기본적으로 리스닝을 시작한 시점부터 토픽에 새로 저장되는 메시지를 반환받도록 동작하며 
--from-beginning 옵션을 이용하면 카프카에 저장돼 있는 모든 데이터를 처음부터 읽겠다는 것을 뜻한다.  
소비자는 새로운 이벤트가 토픽에 들어올때까지 토픽을 리스닝하면서 대기한다.  
```redis
kafka-console-producer --bootstrap-server 127.0.0.1:7000 --topic Email --from-beginning
```

레디스 stream 에서는 데이터를 두 가지 방식으로 읽을 수 있다.  
첫번째는 카프카처럼 실시간으로 처리되는 데이터를 리스낭하는 것이고, 두번째는 Id를 이용해 필요한 데이터를 검색하는 방식이다.  

### 실시가 리스닝
```redis
xread [Count count] [Block milliseconds] streams key [key ...] ID [ID ...]
```
xread 커맨드를 이용하면 실시간으로 stream에 저장되는 데이터를 읽어올 수 있다.  
위의 카프카 예제처럼 email stream에 저장된 데이터를 처음부터 읽어오고 새로운 메시지가 들어올 때까지 계속 토픽을 리스닝하면서
기다리도록 하고 싶으면 다음과 같이 하면 된다.

```redis
xread block 0 streams email 0
```
block 0 은 더이상 스트림에서 가져올 데이터가 없다라도 연결을 끊지 말고 계속 리스닝하라는 의미이다.  
만약 block을 1000을 입력했다면 들어오는 데이터가 없더라도 1000ms 즉 최대 1초 동안 연결을 유지하며 대기하라는 것을 의미한다.  

streams email 0이라는 커맨드는 Email이라는 stream에 저장된 데이터중 id가 0보다 큰값을 읽어오라는 의미이며,
즉 stream에 처음부터 저장된 모든 데이터를 읽어오라는 뜻이다.

### 특정한 데이터 조회
```redis
xrange key start end [count]
xreverange key end start [count]
```

xrange 커맨드를 이용하면 Id를 이용해 원하는 시간대의 데이터를 조회할 수 있다.
가장 작은 ID를 지정하고 싶을때는 -. 가장 높은 ID를 지정하고 싶을때는 +를 사용하면 된다.
```redis
xrange email - + 
```

## 소비자와 소비자 그룹
같은 데이터를 여러 소비자에게 전달하는 것을 팬아웃이라고 한다.  
카프카에서는 같은 토픽을 여러개의 소비자가 읽어가게 함으로써 간단하게 팬아웃할 수 있다.  

레디스 스트림에서도 xread 커맨드를 여러 소비자가 수행한다면 팬아웃이 가능하다.  
여러 소비자를 이용해 한번에 여러 이벤트를 병렬적으로 처리되도록 구성할 수 있다.  
이때 처리되는 메시지의 순서가 보장돼야 하는 경우와 그렇지 않은 경우에 대해 생각해본다.

티켓 판매 서비스에서는 이벤트의 순서를 보장하는 것이 중요하다.  
반면 사용자의 회원 가입 이벤트는 각 사용자의 가압 순서를 엄격하게 지켜지 않아도 되므로 메시지를 생성된 순서대로 처리할 필요가 없다.  
레디스 스트림은 고유한 ID를 받아 순서대로 저장된다.  
반면 카프카에서는 유니크 키는 파티션 내에서만 보장되기 때문에 소비자의 여러 파티션에서 토픽을 읽어갈때에는 데이터의 순서를 보장할 수 없다.  
따라서 카프카에서 메시지 순서가 보장되도록 데이터를 처리하기 위해서는 소비자 그룹을 사용해야 한다.

### 소비자 그룹
카프카에서 소비자 그룹에 여러 소비자를 추가할 수 있으며 이때 소비자는 토픽 내 파티션과 일대일로 연결된다.  
레디스에서도 소비자그룹이라는 개념이 있지만 카프카와 달리 순서에 대한 고민을 하지 않아도 되며, 
소비자 그룹 내의 한 소비자는 다른 소비자가 아직 읽지 않은 데이터만을 읽어간다.  

```redis
xgroup create email emailservicegroup $
```
위 커맨드는 email stream을 읽어가는 emailservicegroup이라는 소비자 그룹을 생성할 수 있으며 $는 형재 시점 이후의 데이터부터 리스닝 하겠다는 것을 의미한다.  

소비자 그룹으로 데이터를 읽어오고 싶다면 xreadgroup 커맨드를 사용하면 된다.
```redis
xreadgroup group emailservicegroup emai;service1 count 1 streams email >
```
emailservicegroup이라는 소비자 그룹이 email stream을 읽어가는데, 이때 emailservice1이라는 소비자가 count만큼의 데이터를 읽어가라는 의미이다.  
매번 소비자가 소비자 그룹을 이용해 작업을 수행할 때마다 그룹 내에서 이 소비자를 고유하게 식별할 수 있는 이름을 지정해야 한다.  
만약 읽지 않은 데이터가 있다면 1개 가져오고 없으면 nil을 반환한다. 각 소비자는 count 커맨드를 이용해 소비할 메시지를 지정할 수 있다.  

stream email > 이 의미하는 것은 email이라는 이름의 stream에서 다른 소비자에게 전달되지 않은 새로운 메시지를 전달하라는 것을 의미한다.  

## ACK와 보류 리스트
장애가 났을때 이를 인지하고 재 처리할 수 있는 기능이 필요하다.  
메시지 브로커는 각 소비자에게 어떤 메시지가 전달 됐고 전달된 메시지의 처리 유무를 인지하고 있어야 한다.  

레디스 stream에서는 소비자 그룹에 속한 소비자가 메시지를 읽어가면 각 소비자별로 읽어간 메시지에 대한 리스트를 새로 생성하며
마지막으로 읽어간 데이터의 ID로 last_delivered_id라는 필드를 생성한다.  

만약 서비스1이 데이터가 처리됐다는 뜻의 ack를 보내면 레디스 stream은 서비스1의 보류 리스트에서 ack를 받은 메시지를 삭제한다.  
즉 보류 리스트를 통해 소비자가 처리한 데이터를 파악할 수 있다.  

### 현재 소비자 그룹에서 보류 중인 리스트가 있는지 확인
```redis
xpending <key> <groupname> [<start-id> <end-id> <count> [<consumer>]]
xpending email emailservicegroup
```
반환되는 현재 소비자 그룹에서 ack를 받지 못해 보류중인 메시지의 개수이며,  
2, 3 번째 값은 각각 보류중인 메시지 ID의 최솟값, 최댓값이다. 그 뒤로는 각 소비자별로 보류중인 리스트가 몇개 있는지 알려준다.  

```redis
xack email emailservicegroup 0-1
```
xack 커맨드를 사용하여 데이터를 처리할 수 있다.  

카프카도 파티션별 오프셋을 관리한다.  
카프카는 내부적으로 _consumer_offsets 라는 토픽에 데이터를 기록하는데, 소비자가 지정된 트래픽의 특정 파티션의 메시지를 읽으면 소비자 그룹, 토픽, 파티션 내용이 통합돼  
저장된다. 카프카에서 오프셋은 소비자가 마지막으로 읽은 위치가 아니라 그 다음위치를 기록한다.  

## 레디스 stream 에서의 at most once, at lease once, exactly once
- at most once: 메시지를 최소한 번 보내는 것을 의미한다. 메시지가 일부 손실되더라도 빠른 응답이 필요한 경우 사용
- at lease onne : 소비자는 받은 메시지를 모두 처리한 뒤 ack를 보낸다.
- exactly once : 모든 메시지가 무조건 한 번씩 전송되는 것을 보장한다는 의미로, 레디스의 set등의 추가적인 자료 구조를 이용해 이미 처리된 메시지를 확인하고 처리되지 않은 메시지만 처리하는 방식으로 구현할 수 있다.

## 메시지의 재 할당
레디스는 소비자에게 장애가 날 경우를 대비해 소비자별 보류 리스트 유지한다.  
소비자 서버에 장애가 복구되지 않는다면 해당 소비자가 처리하던 보류 중인 메시지들은 다른 소비자가 처리해야한다.  
xclaim 커맨드를 이용하면 메시지의 소유권을 다른 소유자에게 할당할 수 있다.  
```redis
xclaim <key> <group> <consumer> <mi-idle-time> <ID-1> <Id-2> ... <ID-N>
```

xclaim 커맨드를 사용할때에는 최소 대기시간(min-idel-time)을 지정해야한다.  
이는 메시지가 보류 상태로 머무른 시간이 최소 대기 시간을 초과한 경ㅇ에만 소유권을 변경할 수 있도록 해서 같은 메시지가 2개의 다른 소비자에게 중복으로 할당 되는 것을 방지한다.  

```redis
emailservice1: xclaim email emailservicegroup emailservice 3 3500000
emailservice2: xclaim email emailservicegroup emailservice 3 3500000
```
위의 커맨드는 emailservice3에 문제가 생겨 이 소비자가 처리하던 메시지를 다른 소비자인 emailservice1, 2가 가져가기 위해 xclaim 커맨드를 실행하는 상황이다.

## 메시지의 자동 재할당
앞에 서는 xpending 으로 보류 멧지를 확인한 뒤, xclaim 명령을 사용해 메시지를 다시 할당하는 상황을 살펴봤다.  

소비자가 직접 보류 했던 메시지 중 하나를 자동으로 가져와서 처리 할 수 있도록하는 xautoclaim 커맨드는 할당 대기 중인 다음 메시지의 ID를 반환하는 방식으로 동작하기 때문에 반복적 호출을 가능하게 한다.
```redis
xautoclaim <key> <group> <consumer> <min-idle-time> <start> [COUNT count] [JUSTID]

xautoclaim email emailservicegroup es1 350000 0-0 count 1
```
첫번째 값으로는 다음으로 대기 중인 보류 메시지의 ID가 반환된다.  
더 이상 대기중인 메시지가 없을 경우 0-0이 반환되고 두번째 반환 값은 소유권이 이전된 메시지의 정보를 제공하며, 
이 정보에는 메시지의 ID와 해당 메시지의 내부 필드-값 쌍이 순서대로 포함돼 있다.  
이 메시지의 소유권은 es1에게로 할당됐음을 알 수 있다.

## 메시지의 수동 재할당
stream 내의 각 메시지는 counter라는 값을 각각 가지고 있다.  
xreadgroup을 이용해 소비자에게 할당하거나 xclaim 커맨드를 이용해 재 할당할 경우 1씩 증가하게 된다.  

만약 메시지에 문제가 있어 처리되지 못할 경우 메시지는 여러 소비자에게 할당 되기를 반복하면서 counter값이 계속 증가하게 된다.  
따라서 counter가 특정 값에 도달하면 이 메시지는 특수한 다른 stream으로 보내, 관리자가 추후에 처리할 수 있도록 하는 것이 현명할 수 있다.  
보통 이런 메시지를 dead letter 라 부른다.

## stream 상태 확인
일반적인 메시징 시스템이 그렇듯 어떤 소비자가 활성화됐는지. 보류된 메시지는 어떤 건지, 어떤 소비자 그룹이 메시지를 처리하고 있는지 등의 상태를 확인하는 커맨드가 없다면
stream을 관리하기 까다로울 것이다.  

xinfo 커맨드를 이용해 stream의 여러 상태를 확인할 수 있으며 이때 사용할 수 있는 기능은 help 커맨드로 확인할 수 있다.  
```redis
xinfo consumers <stream key> <소비자 그룹 이름>
xinfo consumers email emailservicegroup
xinfo gropus email
```
커맨드를 이용해 특정 소비자 그룹에 속한 소비자의 정보를 알 수 있다.  
xinfo groups <stream key> 커맨드를 이용해 stream에 속한 전체 소비자 그룹 list를 볼 수 있다.  
xinfo stream <stream key>를 이용하면 stream 자체의 정보를 알 수 있다.
stream이 내부적으로 어떻게 인코딩되고 있는지 그리고 첫번째와 마지막 메시지의 ID를 표시한다.
