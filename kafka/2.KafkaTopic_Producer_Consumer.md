# 카프카 개요
메세징 시스템에서 메세징을 저장하는곳이 토픽입니다.
메세지를 보내게 되면 토픽에 저장되는데 이 토픽안에는 여러개의 파티션으로 되어 있는데 이 파티션에 저장되는것이다.  
컨슈머들이 파티션에 저장되어있는 내용들을 가져가서 비즈니스적으로 처리하게 메세징 시스템이 되어 있습니다.  

# 토픽 개요
### 토픽은 파티션으로 구성된 일련의 로그 파일이다. 
-  RDBMS 의 Table과 유사한 기능
-  Topic은 Key와 Value 기반의 메시지 구조이며, Value로 어떤 타입의 메시지도 가능(문자열, 숫자값, 객체, Json, Avro, Protobuf등)

Topic은 시간의 흐름에 따라 메시지가 순차적으로 물리적인 파일에 write됨  
offset이 계속 순차적으로 늘어남 -> offset이 작을 수록 과거의 메시지라고 판단하면 된다.  
## Topic과 Patition
Topic은 1개 이상의 파티션을 가질 수 있음.  
Topic의 Partition은 Kafka의 병렬 성능과 가용성 기능의 핵심 요소이며, 메시지는 병렬 성능과 가용성을 고려한 개별 파티션에 분산 저장됨.

### 토픽(Topic과 파티션(Partition), 오프셋(offset)
- 개별 파티션은 정렬되고, 변경 할 수 없는(immutable) 일련의 레코드로 구성된 로그 메시지
- 개별 레코드는 offset으로 불리는 일련 번호를 할당 받음
- 개별 파티션은 다른 파티션과 완전히 독립적임
- 개별 파티션내에서 정렬되고 offset이 할당됨

## 토픽과 파티션의 병렬 분산 처리
메시지는 병렬 성능과 가용성을 고려한 방식으로 토픽내의 개별 파티션들에 분산 저장됨, 또한 토픽의 파티션들은 단일 카프카 브로커 뿐만 아니라 여러개의 카프카 브로커 들에 분산 저장됨.

# Kafka-topics 명령어를 이용하여 Topic 생성 및 정보 확인하기

| 주요 인자       | 설명               |
|-----------------|----------------------|
| --bootstrap-server | Topic을 생성할 Kafka Broker 서버 주소: Port <br>--bootstrap-server local host:9092|
| --create | --topic : 기술된 topic명으로 topic 신규 생성 <br/> --partitions : Topic의 파티션 개수 <br/> --replication-factor : replication 개수|
| --list | 브로커에 있는 Topic들의 리스트|
| --describe | --topic: 기술된 topic명으로 상세 정보 표시|


$CONFLUENT_HOME/bin 하위에 kafka-topics가 있다.  
kafka-topics를 치면 인자를 왜 안줬냐하면서 명령이 끝납니다.  그래서 --로 인자를 줘야합니다.  


## kafka-topics --bootstrap-server localhost:9092 --create --topic test_topic_01
위와 같이 명령어를 입력하면 다음과 같이 워닝 로그가 찍힙니다.  
```
WARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both.
Created topic test_topic_01.
```
_나.을 같이 사용하면 충돌이 나므로 하나만 쓰라는 뜻입니다.

<br/>

## kafka-topics --bootstrap-server localhost:9092 --list
브로커에 생긴 토픽들의 목록을 확인할 수 있습니다.  

<br/>

# 하나의 토픽에 여러개의 파티션 만들기
## kafka-topics --bootstrap-server localhost:9092 --create --topic test_topic_02 --partitions 3
하나의 토픽은 여러개의 파티션을 가질 수 있습니다.  멀티 파트 토픽이 보편적입니다.  
카프카의 핵심은 분산 아키텍쳐이기 때문에 파티션이 핵심입니다.  

<br/>

# 토픽 상세히 조회하기
## kafka-topics --bootstrap-server localhost:9092 --describe --topic test_topic_02


| Topic: test_topic_02  TopicId: nnA1C3ZgSEKNfQlw_TNVzw	PartitionCount: 3 ReplicationFactor: 1 Configs: segment.bytes=1073741824 |
|-----------------|
| Topic: test_topic_02	Partition: 0 Leader: 0	Replicas: 0	Isr: 0 |
| Topic: test_topic_02	Partition: 1 Leader: 0	Replicas: 0	Isr: 0 |
| Topic: test_topic_02	Partition: 2 Leader: 0	Replicas: 0	Isr: 0 |

토픽의 이름과 파티션 번호 리더 등이 다 나옵니다. Replicas는 복제를 뜻합니다.

기본적으로 파티션옵션을 안 주고 토픽을 만들면 파티션이 1개로 만들어줍니다.  이에 대한 옵션은 $CONFLUENT_HOME/etc/kafka/server.properties 파일에
```
# The default number of log partitions per topic. More partitions allow greater
# parallelism for consumption, but this will also result in more files across
# the brokers.
num.partitions=1
```
이렇게 설정되어있습니다.

카프카에대한 로그는 log.dir=/home/min/data/kafka-logs 이렇게 있습니다.  
```
cleaner-offset-checkpoint    meta.properties                   replication-offset-checkpoint  test_topic_02-0  test_topic_02-2
log-start-offset-checkpoint  recovery-point-offset-checkpoint  test_topic_01-0                test_topic_02-1  welcome-topic-0
```
파일들을 보면 test_topic_02-0, 1, 2 이렇게 3개가 있는데 파티션을 3개를 만들어서 0,1,2가 만들어진것을 확인할 수 있습니다.  
cd test_topic_01-0
```
917522 drwxrwxr-x 2 min min     4096  3월 15 23:26 .
917565 drwxrwxr-x 7 min min     4096  3월 15 23:41 ..
917544 -rw-rw-r-- 1 min min 10485760  3월 15 23:26 00000000000000000000.index
917543 -rw-rw-r-- 1 min min        0  3월 15 23:26 00000000000000000000.log
917545 -rw-rw-r-- 1 min min 10485756  3월 15 23:26 00000000000000000000.timeindex
917547 -rw-rw-r-- 1 min min        8  3월 15 23:26 leader-epoch-checkpoint
917546 -rw-rw-r-- 1 min min       43  3월 15 23:26 partition.metadata
```
이렇게 조회할 수 있습니다.  



# 카프카 토픽 삭제하기
## kafka-topics --bootstrap-server localhost:9092 --delete --topic test_topic_02
로그를 확인하면 다음과 같습니다.

```
cd data/kafka-logs
ls
cleaner-offset-checkpoint    recovery-point-offset-checkpoint  test_topic_02-0.3209fef925be4c19b792f7999af6ed37-delete  welcome-topic-0
log-start-offset-checkpoint  replication-offset-checkpoint     test_topic_02-1.403517537a0f43c696eb2bb1d61b1729-delete
meta.properties              test_topic_01-0                   test_topic_02-2.db184eac670f4138ab835421ed32ceae-delete
```
test_topic_02 의 데이터들이 이상한 문자열들이 붙어서 출력됩니다.  바로 지워지진않고 잠시후에 다시 ls 명령어로 확인하면 지워진것을 확인할 수 있습니다.  



# Producer와 Consumer 
## Producer는 Topic에 메시지를 보내는 역할(메시지 write)  
Producer -> Topic 메세지를 보내고 로그파일에 기록합니다.  
Producer는 성능/로드밸런싱/가용성/업무 정합성등을 고려하여 어떤 브로커의 파티션으로 메시지를 보내야할지 전략적으로 결정됨.  
메시지는 다음과 같이 보내집니다.  
ProducerRecord - java 객체로 보내집니다.  
send를 할때 객체직렬화(Seliazer)를 통해 바이트코드로 변환시킵니다.  
여러개의 파티션이있다면 어느 파티션으로 보낼것인지 결정하는 partitionering 단계가 있습니다.  

Record = Message = Event 입니다.  
ProducerRecord : Topic이름, Partition, Key, Value, Header 를 포함해서 보내집니다.  
이 레코드에 반드시 들어가야할것은 Topic(어디로 보낼것인지), Key는 옵셔널로 없어도 되지만 Value는 필수값으로 있어야합니다.  

## Consumer는 Topic에서 메시지를 읽어들밈
여러개의 Consumer들로 구성될 경우 어떤 브로커의 파티션에서 메시지를 읽어들일지 전략적으로 결정함.  
구독하고있는 Topic(채널)에서 Poll하고 하나씩 데이터를 땡겨옵니다.  
땡겨가더라도 토픽의 데이터(로그)는 그대로 유지됩니다.  그래서 다른 컨슈머가와서 이 값들을 다시 가져갈 수 있습니다.  


# Kafka-console-producer와 kafka-console-consumer
$CONFLUENT_HOME/bin 밑에 CLI들이 다 있습니다.  
```
kafka-protobuf-console-producer
kafka-protobuf-console-cunsumer
```
위의 두개가 클라이언트 역할을 커맨드로 하게됩니다.  



#############################################################
#      kafka-console-producer, kafka-console-consumer       #
#############################################################

1. test-topic 토픽 생성하기
kafka-topics --bootstrap-server localhost:9092 --create --topic test-topic

2. kafka-console-producer로 메시지 보내기
kafka-console-producer --bootstrap-server localhost:9092 --topic test-topic

3. kafka-console-consumer로 메시지 읽기
kafka-console-consumer --bootstrap-server localhost:9092 --topic test-topic

2번에서 보내게 되면 offset이 늘어나면서 로그가 쌓이게 됩니다.  
이 과정에서 Producer가 보내기전 시리얼라이즈를 직렬화를 합니다. 이 값들은 다 문자열로 들어갑니다.  

# Cunsumer의 auto.offset.reset
- Consumer가 Topic에 처음 접속하여 Message를 가져올 때 가장 오래된 처음 offset부터(earliest) 가져올 것인지, 가장 최근인 마지막 offset부터 가져올 것인지를 설정하는 파라미터  
- auto.offset.reset = earliest : 처음 offset 부터 읽음
- auto.offset.reset = lastest: 마지막 offset 부터 읽음
- kafka-console-consumer 명령어를 사용할때 --from-beginning을 사용해야만 auto.offset.reset이 earlist로 지정됨